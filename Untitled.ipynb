{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Country', 'HouseholdType'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c5ab98d68458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m# using one got encoding to encode categorical  data , country and  household type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0menc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'HouseholdType'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m# pickle the data to be used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mdata_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Country', 'HouseholdType'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import string\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# data = pd.read_csv('../RHoMIS_ADS_Project_2021/Data/RHoMIS_Indicators.csv',encoding='latin1')\n",
    "data  = pd.read_pickle('./preprocessed_data.pkl')\n",
    "\n",
    "# Data inspection ---------------------------------------------------------------------------\n",
    "def inspect_data(data):\n",
    "\tprint(data.head())\n",
    "\tprint(data.count())\n",
    "\tprint(data.shape)\n",
    "\tprint(data.info())\n",
    "\tfor column in data:\n",
    "\t    print(data[column].describe())\n",
    "\n",
    "#inspect_data(data)\n",
    "\n",
    "# Data Wrangling --------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# replace negative values for features that are bounded to be positive only  as distance metrics like Land cultivated measured in hectares or Income and PPP earned \n",
    "\n",
    "def replace_negative(data,columns):\n",
    "    for col in columns:\n",
    "        data.loc[data[col] < 0] = 0\n",
    "    \n",
    "\n",
    "\n",
    "def drop_columns(data):\n",
    "\tnegative_col = ['LandCultivated', 'LandOwned', 'currency_conversion_factor','total_income_USD_PPP_pHH_Yr','offfarm_income_USD_PPP_pHH_Yr','value_livestock_prod_consumed_USD_PPP_pHH_Yr','NrofMonthsWildFoodCons']\n",
    "\n",
    "\tcategorical_col = ['Country','HouseholdType','Head_EducationLevel', 'WorstFoodSecMonth' ,'BestFoodSecMonth','HFIAS_status']\n",
    "\t# Head_EducationLevel specification about  possible values was not given so we omit this for now \n",
    "\n",
    "\n",
    "\treplace_negative(data, negative_col)\n",
    "\n",
    "\tdata_model = data.copy()\n",
    "# \tdata_model = data.drop(['ID_PROJ','ID_COUNTRY','SURVEY_ID','Region'],axis=1)\n",
    "\tdata_model.drop(['Head_EducationLevel'],axis=1)\n",
    "\tdata_model.set_index('RHoMIS_ID')\n",
    "\treturn data_model\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Print objects\n",
    "for col in data:\n",
    "    if data[col].dtype == object:\n",
    "        print(col)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def replace_missing_with_nan(data_model):\n",
    "\t# replace  HFIAS status with 0 with missing value \n",
    "\tdata_model.loc[data_model['HFIAS_status'] == 0] = np.NaN\n",
    "\n",
    "\n",
    "\t#replace WorstFoodSecMonth and BestFoodSecMonth with No_answer or none with  missing value \n",
    "\tdata_model.loc[data_model['WorstFoodSecMonth'] == 'No_answer'] = np.NaN\n",
    "\tdata_model.loc[data_model['WorstFoodSecMonth'] == 'None'] = np.NaN\n",
    "\tdata_model.loc[data_model['WorstFoodSecMonth'] == 'no_answer'] = np.NaN\n",
    "\tdata_model.loc[data_model['BestFoodSecMonth'] == 'No_answer'] = np.NaN\n",
    "\tdata_model.loc[data_model['BestFoodSecMonth'] == 'no_answer'] = np.NaN\n",
    "\tdata_model.loc[data_model['BestFoodSecMonth'] == 'None'] = np.NaN\n",
    "\n",
    "\t#replace HouseHold type with no answer to missing value \n",
    "# \tdata_model.loc[data_model['HouseholdType'] == 'no_answer'] = np.NaN\n",
    "# \tdata_model.loc[data_model['HouseholdType'] == '0'] = np.NaN\n",
    "\n",
    "\treturn data_model\n",
    "\n",
    "\n",
    "\n",
    "# Dictionary for months in different languange to english\n",
    "\n",
    "\n",
    "def process_months(var, translations):\n",
    "    if var in translations:\n",
    "            return  translations.get(var)\n",
    "    else: return var    \n",
    "                \n",
    "\n",
    "\n",
    "def translate_words(data_model):\n",
    "\tmonths_to_eng = {'ukuboza': 'dec', 'gashyantare' : 'feb', 'kamena' : 'jun', 'mutarama': 'jan', 'nyakanga' : 'jul' , 'nzeri' : 'sep', 'ukwakira' : 'oct',\n",
    "                 'gicurasi' : 'may' , 'werurwe' : 'mar', 'kanama' : 'aug', 'ugushyingo' : 'nov' , 'mata' : 'apr'}\n",
    "\n",
    "\ttranslate = lambda x : process_months(x, months_to_eng)\n",
    "\tdata_model['BestFoodSecMonth'] = data_model.BestFoodSecMonth.apply(translate)\n",
    "\tdata_model['WorstFoodSecMonth'] = data_model.WorstFoodSecMonth.apply(translate)\n",
    "\treturn data_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hfias_status_vis(data_model):\n",
    "\tHFIAS_status_count = data_model['HFIAS_status'].value_counts()\n",
    "\tsns.set(style=\"darkgrid\")\n",
    "\tsns.barplot(x = HFIAS_status_count.index, y = HFIAS_status_count.values, alpha=0.9)\n",
    "\tplt.title('Frequency Distribution of HFIAS_status')\n",
    "\tplt.ylabel('Number of Occurrences', fontsize=12)\n",
    "\tplt.xlabel('HFIAS_status', fontsize=12)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# encode ordinal data \n",
    "HFIAS_status = {'SeverelyFI':0,'ModeratelyFI':1,'MildlyFI':2,'FoodSecure':3 }           \n",
    "data_model['HFIAS_status'] = data_model.HFIAS_status.apply(process_status)\n",
    "\n",
    "data_model['HFIAS_status'].value_counts()\n",
    "\"\"\"\n",
    "\n",
    "#print(data_model['Country'].value_counts())\n",
    "\n",
    "data_model = drop_columns(data)\n",
    "data_model = replace_missing_with_nan(data_model)\n",
    "data_model = translate_words(data_model)\n",
    "\n",
    "# using one got encoding to encode categorical  data , country and  household type \n",
    "enc_data = pd.get_dummies(data_model, prefix=['Nat','Type'], columns=['Country','HouseholdType'])\n",
    "\n",
    "# pickle the data to be used \n",
    "enc_data.to_pickle('preprocessed_data.pkl')\n",
    "#print(enc_data)\n",
    "\n",
    "\n",
    "# Visualizations\n",
    "#hfias_status_vis(data_model)\n",
    "\n",
    "# Imputation ---------------------------------------------------------------------------------\n",
    "\n",
    "# Graph displaying amount of missing data for each featurei\n",
    "\n",
    "def missing_data_vis():\n",
    "\tmissing_data = pd.DataFrame(data[data.columns[data.isnull().any()]].isnull().sum()/len(data)*100)\n",
    "\n",
    "\tnames = []\n",
    "\tfor i in range(len(missing_data)):\n",
    "\t\tnames.append(missing_data.iloc[i].name)\n",
    "\tvalues = []\n",
    "\tfor i in range(len(missing_data)):\n",
    "\t\tvalues.append(missing_data.iloc[i][0])\n",
    "\n",
    "\tdata_1 = {'Features': names,'Missing Data Percentage': values}\n",
    "\n",
    "\t# Dictionary loaded into a DataFrame       \n",
    "\tdf = pd.DataFrame(data=data_1)\n",
    "\tdf.plot.bar(x=\"Features\", y=\"Missing Data Percentage\", title=\"Features with Missing Data\",figsize=(10,6))\n",
    "\tplt.show(block=True)\n",
    "\n",
    "\n",
    "#missing_data_vis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mice_imputer(df):\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(df)\n",
    "    imp.transform(df)\n",
    "#    \n",
    "encoder = OrdinalEncoder()\n",
    "print(enc_data)\n",
    "print(mice_imputer(enc_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
